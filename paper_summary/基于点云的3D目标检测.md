## 基于点云的3D目标检测

##### 概述：

​		3D目标检测解决方式主要分为图像驱动(Image-driven，如Frustum PointNets)、降维(Dimension reduction，如PointPillars)、基于点集网络或稀疏3D卷积(Point set deep nets, Sparse 3D conv, GNNs, 如VoteNet)。

​		室内3D结构更加复杂、物体间挨的更紧密、存在层叠结构；室外铺更开，所以类似鸟瞰图具有一定优势，类似PointPillars；还有类似Votenet、Point-RCNN、Image-drive的方式也可以。

##### 一、PointNet

​		对于PointNet基本思想是对于点云的无序性，需要模型具有置换不变性，即输入点云的顺序变化后，网络的结果不变化，如max公式、求和公式具有置换不变性。

​		所以PointNet基本思想是对每个点进行特征提取(卷积或者全连接)，在通过Max得到全局信息进行输出，核心结构如下：

![image-20220217142937338](../document/images/image-20220217142937338.png)

​		对于实际PointNet的网络结构如下：

![image-20220217143544797](../document/images/image-20220217143544797.png)

​		这里对于input transform、feature  transform等结构后来验证是作用不大的，所以其核心方式就是通过全连接将固定n个点的维度不断升高到1024，之后再纵向维度上取最大值得到全局的1024维特征，之后通过全连接进行k分类；

​		对于语义分割是在n*64的特征项上，每个点从64维特征增加1024维全局特征，之后得到1088维特征，之后对每个点进行m类别分类，完成语义分割任务。

##### 二、PointNet++

​       论文《PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space，2017》是在PointNet的基础上发展而来的，因为PointNet是每个点进行独立的特征提取，最后融合成一个总的特征，但是这个过程中没有对邻域的点云特征进行融合，PointNet++在这方面进行了改进。具体结构与步骤如下所示。

![img](../document/images/clipboard.png)

 		假设点云具有20000个固定输入点：

(1) 选择N1(如2048)簇中心点；

​		首先采用确定的采样点个数作为簇中心店，如2048个簇中心点。该过程称为sampling&grouping过程，取这2048个簇中心点是按照FPS (最远点采样)算法选择出的，即先选择第一个点，选择下一个点时是遍历其他点，选择与已经选择簇中心点距离最远的。最终选择2048个簇中心点；

(2) 设定簇半径，选择固定点数空间点；

​		选择半径0.1、点个数20，对于少于20个点的，则选择簇中心点最近的一个点，复制到20个点，如果多于20个点的，则按照簇中心点距离大小排序，最后选择最近的20个；

(3)每个簇采用pointnet的方式得到K维特征，最终变成(N1, d+C1)；

​		每个点经过MLP从6维(3维空间信息+3维矢量信息)变成K维特征，由于每个簇有20个点，最终通过max得到这个簇的K维信息，max(20,K) = K

(4) K 到C1可以采用多种半径和点数进行特征concatenate；

​		0.1  20、0.2  40、0.4  80

​		每个簇设定多个半径和点数，之后每个设置得到K、M、N维特征，将多个特征concatenate起来变成C1维，即C1 = K + M + N

(5) 由于每一次迭代会得到Nx,Cx维特征；但Cx前3位是空间位置，所以每次迭代都可以继续保留小目标固定簇点数特征；



##### 3D压缩到2D的方法：

##### 二、VoxelNet

​		对于不规则的点云转换成规则的点云，即将一个固定的空间长方体按照长、宽、高等比例划分，得到规则的体素。在一个voxel内的点的信息提取出来得到voxel的表示，如果没有点则使用空的voxel表示，这时可以使用高效的sparse 3D卷积网络进行处理，之后可以压平到BEV平面，之后通过二维的方式进行处理。

![image-20220217151039121](../document/images/image-20220217151039121.png)

##### 三、PointPillar

​		PointPillar在思想上与VoxelNet比较相似，该结构快速将这个柱子高度内的点云通过PointNet等网络结构压缩到平面上，因为在自动驾驶的场景中物体大部分位于一个平面上。之后采用2D的方式进行处理，该结构比VoxelNet更快且更好优化。

![image-20220217184426910](../document/images/image-20220217184426910.png)

##### 四、CenterPoint

​		CenterPoint实际上是在其他backbone结构的基础上进行了任务head的优化。如采用VoxelNet或PointPillar将点云转换到2D空间下的特征图。

​		在2D空间中可以基于anchor的结构进行目标检测，即在2D的平面上铺满anchors。如下：

![image-20220217165322050](../document/images/image-20220217165322050.png)

​		但是在车辆转弯的情况下，anchor的方向与车辆的方向可能不一致，称为rotation misalignment问题。

![image-20220217165522254](../document/images/image-20220217165522254.png)

​		所以CenterPoint不基于anchor进行物体检测，而是通过检测物体的中心点来进行物体检测。得到中心点后，根据中心点的特征进行3D信息的检测，如3D size、朝向。

​		为了得到更好的性能通过2阶段进行检测，即通过1阶段检测到的box，选择中心点以及四条边的中点组合起来进行边框的refine。



##### 直接利用3D的稀疏性进行检测：

​		直接利用3D点云的稀疏性进行检测的核心思想是直接在稀疏点云上进行特征提取，采用的backbone类似PointNet++、Sparse 3D convnet。 相关的网络有PointRCNN、STD、3DSSD、Pv-rcnn等

##### 五、VoteNet

​		论文《Deep Hough Voting for 3D Object Detection in Point Clouds，2019》通过对每个进行特征提取，之后筛选出种子点，每个种子点会进行目标中心点的投票，通过对投票进行聚类得到不同物体中心点，再通过这些投票点进行目标检测。

![image-20220217204620445](../document/images/image-20220217204620445.png)

##### 六、ImVoteNet

